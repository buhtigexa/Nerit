[post_training_corpus]

# Ruta donde se encuentran los archivos para generar del corpus para etiquetado gramatical

corpora:/home/marce/code/virtual_envs/nerit/corpora/postagger/
wordlist_path:/home/marce/code/virtual_envs/nerit/corpora/postagger/wordlists/

# Con el corpus elegido, entrenarlo todo.
training_portion:0.999

# Ruta donde está el archivo de expresiones regulares para añadir al modelo de etiquetado por 1-gramas
regex_file:/home/marce/code/virtual_envs/nerit/data/tokenizers.re

[post_training_corpus.corpus]
# Archivos del corpus ( los que conforman el Corpora )
file_0=esp.tb.train
file_1=gold.tcs

[postaggers]
# Dónde dejar el modelo de etiquetado gramatical una vez generado, qué extensión y cantidad máxima de n-gramas que pretende reconocer
save_to:/home/marce/code/virtual_envs/nerit/tagger_models/
ext_file:.post
max_ngrams:5
# si vamos a utilizar las listas de palabras para que aprenda el etiquetador de 1-gramas
isWordList:True

[postaggers.wordlist]
# Listas de palabras ya categorizadas para añadir al modelo (1-gramas)
CC=conjs.txt
IN=preps.txt
IN=contrx.txt
NNP=nouns_nnp.txt
NN=nouns.txt
VB=verbs.txt
RB=advb.txt
JJ=adjs.txt

[postaggers.regex]
# Expresiones regulares para el etiquetador por 1-gramas,que también se añade al modelo.
# Si no hay match para un 1-grama, etiquetarlo en la clase más frecuente, que será un sustantivo: .*=NN

^\d+$|^[xiv]+$=CD
^.*mente$=RB
^.*([ea]ndo|[ue]zc[ao]|izar)$=VB
^.*(ísim|isim|azo|oso|osa).?$=JJ
.*=NN

# ########################################################################################################################################################
# Chunker.

[chunk_training_corpus]
# Dónde está el directorio del corpus a partir del cual se generará el chunker

corpora:/home/marce/code/virtual_envs/nerit/corpora/tweet_corpus/
training_portion:0.99

[chunk_training_corpus.corpus]

# Qué archivos vas a utilizar para armar el modelo.

file_1=gold.tcs



[chunkers]
# Dónde guardar el chunker generado y con qué extension
save_to:/home/marce/code/virtual_envs/nerit/tagger_models/
ext_file:.chnk

[chunkers.phrases]
# Qué frases o chunks aprenderá el chunker desde el corpus. 

ph1=NOUNP
ph2=VERBP
ph3=ADVBP
ph4=LOCATION
ph5=PREPP
ph6=TIMEP	
ph7=TIMEP
ph8=WEBP
ph9=EVENT
ph10=O

[chunker.features]

# Qué estrategia utilizo para extraer características
featureExtractor:"pipeline.postaggers.generators.features.FeatureExtractor.ContextFeatureExtractor
